{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт всех библиотек"
      ],
      "metadata": {
        "id": "TbGZ4e5aSMbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:20.714776Z",
          "iopub.execute_input": "2023-03-19T18:39:20.715265Z",
          "iopub.status.idle": "2023-03-19T18:39:20.783724Z",
          "shell.execute_reply.started": "2023-03-19T18:39:20.715225Z",
          "shell.execute_reply": "2023-03-19T18:39:20.782582Z"
        },
        "trusted": true,
        "id": "ykhlnBbxfmPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.svm\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from pickle import dump as save\n",
        "from pickle import load as download\n",
        "\n",
        "import torch \n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from torch import cuda\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler"
      ],
      "metadata": {
        "id": "luIvuRrYSVLr",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:36.165473Z",
          "iopub.execute_input": "2023-03-19T18:39:36.165940Z",
          "iopub.status.idle": "2023-03-19T18:39:57.948900Z",
          "shell.execute_reply.started": "2023-03-19T18:39:36.165891Z",
          "shell.execute_reply": "2023-03-19T18:39:57.947672Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции\n",
        "## Для общей работы"
      ],
      "metadata": {
        "id": "GNvABqzJoQbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def statistic(y_pred_test, y_test, y_pred_train, y_train): #статистика\n",
        "    score_table = pd.DataFrame(columns=('train', 'test'))\n",
        "\n",
        "    b_train = balanced_accuracy_score(y_pred_train, y_train)\n",
        "    b_test = balanced_accuracy_score(y_pred_test, y_test)\n",
        "    score_table.loc['balanced_accuracy_score', :] = (b_train, b_test)\n",
        "\n",
        "    a_train = accuracy_score(y_pred_train, y_train)\n",
        "    a_test = accuracy_score(y_pred_test, y_test)\n",
        "    score_table.loc['accuracy_score', :] = (a_train, a_test)\n",
        "\n",
        "    f1_train = f1_score(y_pred_train, y_train, average='weighted')\n",
        "    f1_test = f1_score(y_pred_test, y_test, average='weighted')\n",
        "    score_table.loc['f1 weighted', :] = (f1_train, f1_test)\n",
        "\n",
        "    f1_train = f1_score(y_pred_train, y_train, average='micro')\n",
        "    f1_test = f1_score(y_pred_test, y_test, average='micro')\n",
        "    score_table.loc['f1 micro', :] = (f1_train, f1_test)\n",
        "\n",
        "    f1_train = f1_score(y_pred_train, y_train, average='macro')\n",
        "    f1_test = f1_score(y_pred_test, y_test, average='macro')\n",
        "    score_table.loc['f1 macro', :] = (f1_train, f1_test)\n",
        "\n",
        "    return score_table"
      ],
      "metadata": {
        "id": "2Ntz_bEioaFU",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:57.952695Z",
          "iopub.execute_input": "2023-03-19T18:39:57.953369Z",
          "iopub.status.idle": "2023-03-19T18:39:57.962517Z",
          "shell.execute_reply.started": "2023-03-19T18:39:57.953323Z",
          "shell.execute_reply": "2023-03-19T18:39:57.961530Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cm_plot(y_test, y_pred, y_type): #матрица ошибок\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    # Normalise\n",
        "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    sns.heatmap(cmn, cmap='Blues', annot=True, fmt='.2f')\n",
        "    sns.set(font_scale=1.3)\n",
        "    plt.title(f'Confusion Matrix of {y_type}')\n",
        "\n",
        "    return plt.show()"
      ],
      "metadata": {
        "id": "fMn8kwSKodQM",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:57.965011Z",
          "iopub.execute_input": "2023-03-19T18:39:57.965295Z",
          "iopub.status.idle": "2023-03-19T18:39:57.990383Z",
          "shell.execute_reply.started": "2023-03-19T18:39:57.965254Z",
          "shell.execute_reply": "2023-03-19T18:39:57.989202Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Классы данных"
      ],
      "metadata": {
        "id": "ADiKyeFtb4Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_audio(Dataset):\n",
        "    def __init__(self, x, y=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return np.array([self.x[idx]]), self.y[idx]"
      ],
      "metadata": {
        "id": "qkqi0ktFofhO",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:58.013158Z",
          "iopub.execute_input": "2023-03-19T18:39:58.013550Z",
          "iopub.status.idle": "2023-03-19T18:39:58.025029Z",
          "shell.execute_reply.started": "2023-03-19T18:39:58.013514Z",
          "shell.execute_reply": "2023-03-19T18:39:58.024051Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentData(Dataset):\n",
        "    def __init__(self, dataframe, y, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = pd.concat([dataframe, y], axis=1)\n",
        "        self.text = dataframe.Utterance\n",
        "        self.targets = y\n",
        "        self.max_len = max_len\n",
        "        self.utt = dataframe.Utterance_ID\n",
        "        self.dia = dataframe.Dialogue_ID\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
        "            'utt': self.utt[index],\n",
        "            'dia': self.dia[index]\n",
        "        }"
      ],
      "metadata": {
        "id": "2qFuMhnkWfvx",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:58.028379Z",
          "iopub.execute_input": "2023-03-19T18:39:58.028721Z",
          "iopub.status.idle": "2023-03-19T18:39:58.039328Z",
          "shell.execute_reply.started": "2023-03-19T18:39:58.028692Z",
          "shell.execute_reply": "2023-03-19T18:39:58.038122Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## НС"
      ],
      "metadata": {
        "id": "d3y69jE5ctGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        #secret :)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        \n",
        "        #secret :))\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:58.051300Z",
          "iopub.execute_input": "2023-03-19T18:39:58.052282Z",
          "iopub.status.idle": "2023-03-19T18:39:58.066305Z",
          "shell.execute_reply.started": "2023-03-19T18:39:58.052245Z",
          "shell.execute_reply": "2023-03-19T18:39:58.065287Z"
        },
        "trusted": true,
        "id": "kaTmhoLcfmPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Работа с моделями\n",
        "## Aудио"
      ],
      "metadata": {
        "id": "5f3f7ni6gkbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('/kaggle/input/pooling/train_openSMILE.csv', header=0, index_col='file', sep=',')\n",
        "X_val = pd.read_csv('/kaggle/input/pooling/dev_openSMILE.csv', header=0, index_col='file', sep=',')\n",
        "X_test = pd.read_csv('/kaggle/input/pooling/test_openSMILE.csv', header=0, index_col='file', sep=',')\n",
        "\n",
        "y_train = X_train['target']\n",
        "X_train.drop(['target'], inplace=True, axis=1)\n",
        "\n",
        "y_train = y_train.replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])\n",
        "y_test = X_test['target']\n",
        "X_test.drop(['target'], inplace=True, axis=1)\n",
        "\n",
        "y_test = y_test.replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])\n",
        "\n",
        "y_val = X_val['target']\n",
        "X_val.drop(['target'], inplace=True, axis=1)\n",
        "\n",
        "y_val = y_val.replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])"
      ],
      "metadata": {
        "id": "CgBdLeGBg5Re",
        "execution": {
          "iopub.status.busy": "2023-03-19T10:33:35.819069Z",
          "iopub.execute_input": "2023-03-19T10:33:35.819594Z",
          "iopub.status.idle": "2023-03-19T10:34:01.724414Z",
          "shell.execute_reply.started": "2023-03-19T10:33:35.819530Z",
          "shell.execute_reply": "2023-03-19T10:34:01.723371Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/kaggle/input/roberta-meld/scaler.pickle', 'rb')\n",
        "scaler = download(f)\n",
        "f.close\n",
        "\n",
        "f = open('/kaggle/input/roberta-meld/PCA.pickle', 'rb')\n",
        "pca = download(f)\n",
        "f.close\n",
        "\n",
        "f = open('/kaggle/input/roberta-meld/SVC_model_audio_36score.pickle', 'rb')\n",
        "classifier = download(f)\n",
        "f.close"
      ],
      "metadata": {
        "id": "OOW7XIoKh_yi",
        "execution": {
          "iopub.status.busy": "2023-03-15T09:40:15.027708Z",
          "iopub.execute_input": "2023-03-15T09:40:15.028047Z",
          "iopub.status.idle": "2023-03-15T09:40:17.195524Z",
          "shell.execute_reply.started": "2023-03-15T09:40:15.028007Z",
          "shell.execute_reply": "2023-03-15T09:40:17.194099Z"
        },
        "trusted": true,
        "outputId": "f9a1cf58-902e-477b-dd9b-9a933561d500"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<function BufferedReader.close>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_prob(data):\n",
        "    targets = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'sadness', 4: 'neutral', 5: 'joy', \n",
        "                                               6: 'surprise'}\n",
        "    probs_Audio = pd.DataFrame(columns=('name', 'anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise', 'targets'))\n",
        "    \n",
        "    for index in data.index:\n",
        "        row = np.array(data.loc[index])\n",
        "        row = row.reshape(-1, 1).T\n",
        "        row = scaler.transform(row)\n",
        "        row = pca.transform(row)\n",
        "        probs = classifier.predict_proba(row)\n",
        "        \n",
        "        l = tuple([index[:-4]] + list(probs[0]) + [targets[probs.argmax()]])\n",
        "        probs_Audio.loc[probs_Audio.shape[0], :] = l\n",
        "\n",
        "    \n",
        "    return probs_Audio"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T09:40:17.196938Z",
          "iopub.execute_input": "2023-03-15T09:40:17.197276Z",
          "iopub.status.idle": "2023-03-15T09:40:17.206564Z",
          "shell.execute_reply.started": "2023-03-15T09:40:17.197244Z",
          "shell.execute_reply": "2023-03-15T09:40:17.205116Z"
        },
        "trusted": true,
        "id": "shUZMZPffmPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_Audio_dev = get_audio_prob(X_val)\n",
        "probs_Audio_train = get_audio_prob(X_train)\n",
        "probs_Audio_test = get_audio_prob(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T09:40:17.208212Z",
          "iopub.execute_input": "2023-03-15T09:40:17.208789Z",
          "iopub.status.idle": "2023-03-15T09:53:25.582975Z",
          "shell.execute_reply.started": "2023-03-15T09:40:17.208749Z",
          "shell.execute_reply": "2023-03-15T09:53:25.580980Z"
        },
        "trusted": true,
        "id": "vVDEq98CfmPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_Audio_dev = probs_Audio_dev.set_index('name')\n",
        "probs_Audio_train = probs_Audio_train.set_index('name')\n",
        "probs_Audio_test = probs_Audio_test.set_index('name')\n",
        "\n",
        "probs_Audio_train.to_csv('probs_audio_train.csv')\n",
        "probs_Audio_dev.to_csv('probs_audio_dev.csv')\n",
        "probs_Audio_test.to_csv('probs_audio_test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T09:53:25.591282Z",
          "iopub.execute_input": "2023-03-15T09:53:25.592326Z",
          "iopub.status.idle": "2023-03-15T09:53:25.779226Z",
          "shell.execute_reply.started": "2023-03-15T09:53:25.592245Z",
          "shell.execute_reply": "2023-03-15T09:53:25.777613Z"
        },
        "trusted": true,
        "id": "HeeI3_JmfmPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Как вытащить роберту и словарь"
      ],
      "metadata": {
        "id": "EndgJnDJhNFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
      ],
      "metadata": {
        "id": "QIjTTXKNhRdc",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:58.067668Z",
          "iopub.execute_input": "2023-03-19T18:39:58.068409Z",
          "iopub.status.idle": "2023-03-19T18:39:59.776360Z",
          "shell.execute_reply.started": "2023-03-19T18:39:58.068372Z",
          "shell.execute_reply": "2023-03-19T18:39:59.775270Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "3af9921639164f50aef08d29d2abd573",
            "d5c539da59b447fea9b57a42317ff35f",
            "7b158a1d9dcb4aeea3ef01a4e9b04b20"
          ]
        },
        "outputId": "0afc923e-34e9-4b91-c82f-5f76a99735f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af9921639164f50aef08d29d2abd573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5c539da59b447fea9b57a42317ff35f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b158a1d9dcb4aeea3ef01a4e9b04b20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/kaggle/input/pooling/pytorch_roberta_sentiment_65-32.bin')\n",
        "\n",
        "model.eval()\n",
        "None"
      ],
      "metadata": {
        "id": "jcPEjcudjaUx",
        "execution": {
          "iopub.status.busy": "2023-03-19T18:40:00.011648Z",
          "iopub.execute_input": "2023-03-19T18:40:00.012290Z",
          "iopub.status.idle": "2023-03-19T18:40:11.714344Z",
          "shell.execute_reply.started": "2023-03-19T18:40:00.012251Z",
          "shell.execute_reply": "2023-03-19T18:40:11.713249Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/pooling/train_sent_emo.csv', delimiter=',', header=0)\n",
        "val = pd.read_csv('/kaggle/input/pooling/dev_sent_emo.csv', delimiter=',', header=0)\n",
        "test = pd.read_csv('/kaggle/input/pooling/test_sent_emo.csv', delimiter=',', header=0)\n",
        "\n",
        "train['Utterance'] = train['Utterance'].str.replace('\\x92','\\'')\n",
        "val['Utterance'] = val['Utterance'].str.replace('\\x92','\\'')\n",
        "test['Utterance'] = test['Utterance'].str.replace('\\x92','\\'')\n",
        "\n",
        "y_train = train['Emotion'].replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])\n",
        "y_val = val['Emotion'].replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])\n",
        "y_test = test['Emotion'].replace(['anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise'], \n",
        "                                              [0, 1, 2, 3, 4, 5, 6])\n",
        "\n",
        "train.drop(['Sr No.', 'Speaker', 'Emotion', 'Sentiment', 'Season', 'Episode', 'StartTime', 'EndTime'], axis=1, inplace=True)\n",
        "val.drop(['Sr No.', 'Speaker', 'Emotion', 'Sentiment', 'Season', 'Episode', 'StartTime', 'EndTime'], axis=1, inplace=True)\n",
        "test.drop(['Sr No.', 'Speaker', 'Emotion', 'Sentiment', 'Season', 'Episode', 'StartTime', 'EndTime'], axis=1, inplace=True)\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:39:59.777725Z",
          "iopub.execute_input": "2023-03-19T18:39:59.778163Z",
          "iopub.status.idle": "2023-03-19T18:40:00.009854Z",
          "shell.execute_reply.started": "2023-03-19T18:39:59.778125Z",
          "shell.execute_reply": "2023-03-19T18:40:00.008810Z"
        },
        "trusted": true,
        "id": "HSLZQtHSfmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = { \n",
        "    #secret\n",
        "             }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:40:11.715904Z",
          "iopub.execute_input": "2023-03-19T18:40:11.716279Z",
          "iopub.status.idle": "2023-03-19T18:40:11.723036Z",
          "shell.execute_reply.started": "2023-03-19T18:40:11.716240Z",
          "shell.execute_reply": "2023-03-19T18:40:11.721680Z"
        },
        "trusted": true,
        "id": "xvxTsqBafmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = SentimentData(train, y_train, tokenizer, parameters['max_len'])\n",
        "val_set = SentimentData(val, y_val, tokenizer, parameters['max_len'])\n",
        "test_set = SentimentData(test, y_test, tokenizer, parameters['max_len'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:40:11.724655Z",
          "iopub.execute_input": "2023-03-19T18:40:11.725892Z",
          "iopub.status.idle": "2023-03-19T18:40:11.738118Z",
          "shell.execute_reply.started": "2023-03-19T18:40:11.725851Z",
          "shell.execute_reply": "2023-03-19T18:40:11.737033Z"
        },
        "trusted": true,
        "id": "DMlgQyi4fmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': parameters['batch_size'],\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "val_params = {'batch_size': parameters['batch_size'],\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': parameters['batch_size'],\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "train_loader = DataLoader(train_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "test_loader = DataLoader(test_set, **test_params)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:40:11.741019Z",
          "iopub.execute_input": "2023-03-19T18:40:11.742024Z",
          "iopub.status.idle": "2023-03-19T18:40:11.755059Z",
          "shell.execute_reply.started": "2023-03-19T18:40:11.741971Z",
          "shell.execute_reply": "2023-03-19T18:40:11.753920Z"
        },
        "trusted": true,
        "id": "AUPLRHJ6fmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentData(Dataset):\n",
        "    def __init__(self, text, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = text\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            # pad_to_max_length=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'text': self.text\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T18:54:05.910433Z",
          "iopub.execute_input": "2023-03-19T18:54:05.911244Z",
          "iopub.status.idle": "2023-03-19T18:54:05.919653Z",
          "shell.execute_reply.started": "2023-03-19T18:54:05.911176Z",
          "shell.execute_reply": "2023-03-19T18:54:05.918558Z"
        },
        "trusted": true,
        "id": "sobghRXyfmPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T17:44:52.985009Z",
          "iopub.execute_input": "2023-03-19T17:44:52.985389Z",
          "iopub.status.idle": "2023-03-19T17:44:52.997271Z",
          "shell.execute_reply.started": "2023-03-19T17:44:52.985351Z",
          "shell.execute_reply": "2023-03-19T17:44:52.996225Z"
        },
        "trusted": true,
        "id": "hvG9C5yofmPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(model, loader):\n",
        "    \n",
        "    model.eval()\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "    targets = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'sadness', 4: 'neutral', 5: 'joy', \n",
        "                                               6: 'surprise'}\n",
        "    probs_Text = pd.DataFrame(columns=('name', 'anger', 'disgust', 'fear', 'sadness', 'neutral', 'joy', \n",
        "                                               'surprise', 'targets'))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _, data in (enumerate(loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            \n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            ind_targed = int(outputs.argmax(1).int())\n",
        "            \n",
        "            name = ['dia' + str(int(data['dia'].int())) + '_utt' + str(int(data['utt'].int()))]\n",
        "            l = tuple(name + list(softmax(np.array(outputs.cpu()))[0]) + [targets[ind_targed]])\n",
        "            probs_Text.loc[probs_Text.shape[0], :] = l\n",
        "\n",
        "    \n",
        "    return probs_Text\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T17:44:52.999209Z",
          "iopub.execute_input": "2023-03-19T17:44:52.999966Z",
          "iopub.status.idle": "2023-03-19T17:44:53.010958Z",
          "shell.execute_reply.started": "2023-03-19T17:44:52.999910Z",
          "shell.execute_reply": "2023-03-19T17:44:53.009902Z"
        },
        "trusted": true,
        "id": "5EndUQK2fmPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_Text_val = get_probs(model, val_loader)\n",
        "probs_Text_train = get_probs(model, train_loader)\n",
        "probs_Text_test = get_probs(model, test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T17:44:53.012510Z",
          "iopub.execute_input": "2023-03-19T17:44:53.012929Z",
          "iopub.status.idle": "2023-03-19T17:48:58.739236Z",
          "shell.execute_reply.started": "2023-03-19T17:44:53.012888Z",
          "shell.execute_reply": "2023-03-19T17:48:58.737853Z"
        },
        "trusted": true,
        "id": "cVVLjZhUfmPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_Text_val = probs_Text_val.set_index('name')\n",
        "probs_Text_train = probs_Text_train.set_index('name')\n",
        "probs_Text_test = probs_Text_test.set_index('name')\n",
        "\n",
        "probs_Text_train.to_csv('probs_text_train.csv')\n",
        "probs_Text_val.to_csv('probs_text_dev.csv')\n",
        "probs_Text_test.to_csv('probs_text_test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T17:48:58.743726Z",
          "iopub.execute_input": "2023-03-19T17:48:58.744120Z",
          "iopub.status.idle": "2023-03-19T17:48:58.834187Z",
          "shell.execute_reply.started": "2023-03-19T17:48:58.744087Z",
          "shell.execute_reply": "2023-03-19T17:48:58.833165Z"
        },
        "trusted": true,
        "id": "fSVglQJtfmPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emb(model, loader):\n",
        "    \n",
        "    dict_out_pooler = {}\n",
        "    dict_out_dim = {}\n",
        "    model.eval()\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "    targets = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'sadness', 4: 'neutral', 5: 'joy', \n",
        "                                               6: 'surprise'}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _, data in (enumerate(loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            ind_target = int(data['targets'].to(device, dtype = torch.long).int())\n",
        "            \n",
        "            name = 'dia' + str(int(data['dia'].int())) + '_utt' + str(int(data['utt'].int()))\n",
        "            \n",
        "            pooler_outp = model.l1(input_ids=ids, attention_mask=mask, \n",
        "                     token_type_ids=token_type_ids).pooler_output\n",
        "            \n",
        "            emb_pooler = np.array(pooler_outp[0].tolist())\n",
        "            emb_out_dim = np.array(model.pre_classifier(pooler_outp)[0].tolist())\n",
        "            \n",
        "            dict_out_pooler[name] = {'emb': emb_pooler, 'target': targets[ind_target]}\n",
        "            dict_out_dim[name] = {'emb': emb_out_dim, 'target': targets[ind_target]}\n",
        "            \n",
        "\n",
        "    return dict_out_pooler, dict_out_dim\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T11:15:30.348457Z",
          "iopub.execute_input": "2023-03-19T11:15:30.348738Z",
          "iopub.status.idle": "2023-03-19T11:15:30.362723Z",
          "shell.execute_reply.started": "2023-03-19T11:15:30.348712Z",
          "shell.execute_reply": "2023-03-19T11:15:30.361655Z"
        },
        "trusted": true,
        "id": "CIZN565cfmPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pooler, dev_dim = get_emb(model, val_loader)\n",
        "train_pooler, train_dim = get_emb(model, train_loader)\n",
        "test_pooler, test_dim = get_emb(model, test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T11:18:52.430071Z",
          "iopub.execute_input": "2023-03-19T11:18:52.431020Z",
          "iopub.status.idle": "2023-03-19T11:22:53.261165Z",
          "shell.execute_reply.started": "2023-03-19T11:18:52.430967Z",
          "shell.execute_reply": "2023-03-19T11:22:53.260058Z"
        },
        "trusted": true,
        "id": "1vBh_ZhnfmPs",
        "outputId": "218a867d-21b0-4ad3-a310-25742192a146"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('dev_text_emb_768', dev_pooler)\n",
        "np.save('train_text_emb_768', train_pooler)\n",
        "np.save('test_text_emb_768', test_pooler)\n",
        "\n",
        "np.save('dev_text_emb_512', dev_dim)\n",
        "np.save('train_text_emb_512', train_dim)\n",
        "np.save('test_text_emb_512', test_dim)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-19T11:23:20.628090Z",
          "iopub.execute_input": "2023-03-19T11:23:20.628468Z",
          "iopub.status.idle": "2023-03-19T11:23:21.065363Z",
          "shell.execute_reply.started": "2023-03-19T11:23:20.628433Z",
          "shell.execute_reply": "2023-03-19T11:23:21.064269Z"
        },
        "trusted": true,
        "id": "P08OCxxnfmPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}